{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM+DECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'node_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Extract ECT features\u001b[39;00m\n\u001b[32m     86\u001b[39m ect_extractor = ECTFeatureExtractor(ect_config=ect_config, directions=v).to(DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m ect_features_train = \u001b[43mect_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.detach().cpu().numpy().reshape(\u001b[38;5;28mlen\u001b[39m(y_train), -\u001b[32m1\u001b[39m)\n\u001b[32m     88\u001b[39m ect_features_test = ect_extractor(test_batch.to(DEVICE)).detach().cpu().numpy().reshape(\u001b[38;5;28mlen\u001b[39m(y_test), -\u001b[32m1\u001b[39m)\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Train SVM with RBF kernel\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Keshav Chandak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Keshav Chandak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mECTFeatureExtractor.forward\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     ect_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mect_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Uses batch.x (original features)\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ect_features\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Keshav Chandak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Keshav Chandak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Keshav Chandak\\OneDrive\\Desktop\\semester 8\\Topo_PE\\WDECT\\wect.py:110\u001b[39m, in \u001b[36mECTLayer.forward\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Batch) -> torch.FloatTensor:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     ect = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_ect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmovedim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m normalize(ect) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.normalized \u001b[38;5;28;01melse\u001b[39;00m ect.squeeze()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Keshav Chandak\\OneDrive\\Desktop\\semester 8\\Topo_PE\\WDECT\\wect.py:46\u001b[39m, in \u001b[36mcompute_ect_points\u001b[39m\u001b[34m(batch, v, lin)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_ect_points\u001b[39m(batch: Batch, v: torch.FloatTensor, lin: torch.FloatTensor):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     weights = batch.node_weights \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode_weights\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch.ones(batch.x.size(\u001b[32m0\u001b[39m), device=batch.x.device)\n\u001b[32m     47\u001b[39m     nh = (batch.x * weights.unsqueeze(\u001b[32m1\u001b[39m)) @ v\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m compute_ecc(nh, batch.batch, lin)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Keshav Chandak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch_geometric\\data\\data.py:561\u001b[39m, in \u001b[36mData.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m_store\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m object was created by an older version of PyG. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf this error occurred while loading an already existing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdataset, remove the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprocessed/\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directory in the dataset\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    560\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mroot folder and try again.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Keshav Chandak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch_geometric\\data\\storage.py:96\u001b[39m, in \u001b[36mBaseStorage.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'GlobalStorage' object has no attribute 'node_weights'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, Batch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wect import ECTLayer, ECTConfig  \n",
    "\n",
    "# Set device\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "# Function to load the Digits dataset\n",
    "def load_digits_data():\n",
    "    digits = load_digits()\n",
    "    X, y = digits.data, digits.target\n",
    "    return X, y\n",
    "\n",
    "# Define RBF kernel function for DECT loss\n",
    "def rbf_kernel(x1, x2, gamma=1.0):\n",
    "    distance = torch.cdist(x1, x2, p=2)\n",
    "    return torch.exp(-gamma * distance ** 2)\n",
    "\n",
    "# Custom DECT loss class (adjusted for binary illustration in a multi-class context)\n",
    "class DECTLoss(nn.Module):\n",
    "    def __init__(self, gamma=1.0):\n",
    "        super(DECTLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, ect_features, labels):\n",
    "        kernel_matrix = rbf_kernel(ect_features, ect_features, self.gamma)\n",
    "        # Labels should be -1 and 1 for binary hinge loss\n",
    "        margins = torch.matmul(kernel_matrix, labels.float())\n",
    "        loss = torch.mean(torch.clamp(1 - margins, min=0))\n",
    "        return loss\n",
    "\n",
    "# ECT feature extractor using original features\n",
    "class ECTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, ect_config, directions):\n",
    "        super(ECTFeatureExtractor, self).__init__()\n",
    "        self.ect_layer = ECTLayer(ect_config, v=directions)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ect_features = self.ect_layer(batch)  # Uses batch.x (original features)\n",
    "        return ect_features\n",
    "\n",
    "# Load and preprocess the Digits dataset\n",
    "X, y = load_digits_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Convert to PyTorch Geometric format\n",
    "train_data = [Data(x=X_train[i:i+1]) for i in range(len(X_train))]\n",
    "train_batch = Batch.from_data_list(train_data)\n",
    "\n",
    "test_data = [Data(x=X_test[i:i+1]) for i in range(len(X_test))]\n",
    "test_batch = Batch.from_data_list(test_data)\n",
    "\n",
    "# Set ECT parameters\n",
    "num_features = 64  # Digits dataset has 64 features (8x8 images)\n",
    "num_thetas = 128\n",
    "v = torch.randn(num_features, num_thetas)  # Random directions in 64D\n",
    "\n",
    "ect_config = ECTConfig(\n",
    "    ect_type=\"points\",\n",
    "    bump_steps=128,\n",
    "    radius=1.0,\n",
    "    normalized=False,\n",
    "    fixed=True,\n",
    ")\n",
    "\n",
    "# Extract ECT features\n",
    "ect_extractor = ECTFeatureExtractor(ect_config=ect_config, directions=v).to(DEVICE)\n",
    "ect_features_train = ect_extractor(train_batch.to(DEVICE)).detach().cpu().numpy().reshape(len(y_train), -1)\n",
    "ect_features_test = ect_extractor(test_batch.to(DEVICE)).detach().cpu().numpy().reshape(len(y_test), -1)\n",
    "\n",
    "# Train SVM with RBF kernel\n",
    "svm_model = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\")\n",
    "svm_model.fit(ect_features_train, y_train.numpy())\n",
    "\n",
    "# Evaluate SVM predictions\n",
    "predicted_labels = svm_model.predict(ect_features_test)\n",
    "accuracy = accuracy_score(y_test.numpy(), predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Compute DECT loss for illustration (class 0 vs. rest)\n",
    "y_train_binary = (y_train == 0).long() * 2 - 1  # 1 if y==0, else -1\n",
    "dect_loss_fn = DECTLoss(gamma=1.0)\n",
    "dect_loss = dect_loss_fn(torch.tensor(ect_features_train), y_train_binary)\n",
    "print(f\"DECT Loss (for class 0 vs. rest): {dect_loss.item():.4f}\")\n",
    "\n",
    "# Visualize the first two ECT features with predicted labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(ect_features_test[:, 0], ect_features_test[:, 1], c=predicted_labels, cmap=\"viridis\", alpha=0.7)\n",
    "plt.title(\"SVM Decision Boundaries (Using ECT Features) - Digits Dataset\")\n",
    "plt.xlabel(\"ECT Feature 1\")\n",
    "plt.ylabel(\"ECT Feature 2\")\n",
    "plt.colorbar(label=\"Predicted Digit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN+DECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate random directions for ECT projection\n",
    "def generate_random_directions(num_directions, dim):\n",
    "    directions = torch.randn(dim, num_directions)\n",
    "    directions = directions / torch.norm(directions, dim=0, keepdim=True)\n",
    "    return directions\n",
    "\n",
    "# ECT Layer\n",
    "class ECTLayer(nn.Module):\n",
    "    def __init__(self, v):\n",
    "        super(ECTLayer, self).__init__()\n",
    "        self.v = v  # Random directions\n",
    "\n",
    "    def forward(self, batch):\n",
    "        nh = batch.x @ self.v  # Project features onto directions\n",
    "        return nh\n",
    "\n",
    "# ECT Classifier\n",
    "class ECTClassifier(nn.Module):\n",
    "    def __init__(self, dim, num_directions, hidden_dim, num_classes):\n",
    "        super(ECTClassifier, self).__init__()\n",
    "        self.v = generate_random_directions(num_directions, dim)\n",
    "        self.ect_layer = ECTLayer(self.v)\n",
    "        self.fc1 = nn.Linear(num_directions, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ect_features = self.ect_layer(batch)\n",
    "        ect_features = ect_features.view(-1, ect_features.size(1))\n",
    "        x = F.relu(self.fc1(ect_features))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load and prepare data\n",
    "def load_digits_data():\n",
    "    data = load_digits()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    train_data = [Data(x=torch.tensor(X_train[i:i+1], dtype=torch.float32),\n",
    "                       y=torch.tensor([y_train[i]], dtype=torch.long))\n",
    "                  for i in range(len(X_train))]\n",
    "    test_data = [Data(x=torch.tensor(X_test[i:i+1], dtype=torch.float32),\n",
    "                      y=torch.tensor([y_test[i]], dtype=torch.long))\n",
    "                 for i in range(len(X_test))]\n",
    "    return train_data, test_data\n",
    "\n",
    "# Training function\n",
    "def train(model, train_data, num_epochs=200):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        batch = Batch.from_data_list(train_data)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, data_list):\n",
    "    model.eval()\n",
    "    batch = Batch.from_data_list(data_list)\n",
    "    with torch.no_grad():\n",
    "        out = model(batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = (pred == batch.y).sum().item()\n",
    "        accuracy = correct / len(batch.y)\n",
    "    return accuracy\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Parameters\n",
    "    dim = 64  # Feature dimension for Digits dataset\n",
    "    num_directions = 128\n",
    "    hidden_dim = 64\n",
    "    num_classes = 10  # Digits 0-9\n",
    "    num_epochs = 200\n",
    "\n",
    "    # Load data\n",
    "    train_data, test_data = load_digits_data()\n",
    "\n",
    "    # Initialize and train model\n",
    "    model = ECTClassifier(dim, num_directions, hidden_dim, num_classes)\n",
    "    train(model, train_data, num_epochs)\n",
    "\n",
    "    # Compute accuracies\n",
    "    train_accuracy = evaluate(model, train_data)\n",
    "    test_accuracy = evaluate(model, test_data)\n",
    "\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
